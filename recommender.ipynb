{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kakao arena 2nd Competition\n",
    "# \"브런치 사용자를 위한 글 추천 대회\"\n",
    "### brunch 데이터를 활용해 사용자의 취향에 맞는 글을 예측하는 대회\n",
    "* 공식 홈페이지: https://arena.kakao.com/c/2\n",
    "* 베이스 코드: https://github.com/kakao-arena/brunch-article-recommendation\n",
    "\n",
    "### BrunchRec \n",
    "* designed by **datartist**\n",
    "* 깃헙 주소: https://github.com/jihoo-kim/BrunchRec  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 및 원본데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 라이브러리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import pickle\n",
    "import warnings\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "directory = './res/'\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 원본데이터\n",
    "\n",
    "# users  // DataFrame (310758, 3)\n",
    "users = pd.read_json(directory + '/users.json', lines=True)\n",
    "\n",
    "# magazine  // DataFrame (27967, 2)\n",
    "magazine = pd.read_json(directory + 'magazine.json', lines=True)\n",
    "\n",
    "# metadata  // DataFrame (643104, 9)\n",
    "metadata = pd.read_json(directory + 'metadata.json', lines=True)\n",
    "\n",
    "# dev.users  // List (3000)\n",
    "f = open('./res/predict/dev.users')\n",
    "dev_users = f.read().splitlines()\n",
    "f.close()\n",
    "\n",
    "# test.users  // List (5000)\n",
    "f = open('./res/predict/test.users')\n",
    "test_users = f.read().splitlines()\n",
    "f.close()\n",
    "\n",
    "# read  // DataFrame (3507097, 5)\n",
    "read_file_lst = glob.glob('./res/read/*')\n",
    "exclude_file_lst = ['read.tar']\n",
    "read_df_lst = []\n",
    "for f in read_file_lst:\n",
    "    file_name = os.path.basename(f)\n",
    "    if file_name in exclude_file_lst:\n",
    "        print(file_name)\n",
    "    else:\n",
    "        df_temp = pd.read_csv(f, header=None, names=['raw'])\n",
    "        df_temp['dt'] = file_name[:8]\n",
    "        df_temp['hr'] = file_name[8:10]\n",
    "        df_temp['user_id'] = df_temp['raw'].str.split(' ').str[0]\n",
    "        df_temp['article_id'] = df_temp['raw'].str.split(' ').str[1:].str.join(' ').str.strip()\n",
    "        read_df_lst.append(df_temp)\n",
    "read = pd.concat(read_df_lst)\n",
    "\n",
    "# read_raw  // DataFrame (22110706, 4)\n",
    "def chainer(s):\n",
    "    return list(chain.from_iterable(s.str.split(' ')))\n",
    "\n",
    "read_cnt_by_user = read['article_id'].str.split(' ').map(len)\n",
    "\n",
    "read_raw = pd.DataFrame({'dt': np.repeat(read['dt'], read_cnt_by_user),\n",
    "                         'hr': np.repeat(read['hr'], read_cnt_by_user),\n",
    "                         'user_id': np.repeat(read['user_id'], read_cnt_by_user),\n",
    "                         'article_id': chainer(read['article_id'])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 전처리 관련 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read_raw 'dt' 전처리 (날짜 컬럼의 자료형 변환 string -> int)\n",
    "def read_raw_dt_preprocessing(read_raw_df):\n",
    "    \n",
    "    if type(read_raw_df['dt'].values[0]) == type('string'):\n",
    "        dt = read_raw_df['dt'].tolist()\n",
    "        read_raw_df['dt'] = [int (i) for i in dt]\n",
    "        print('preprocessing completed!')\n",
    "\n",
    "    else:\n",
    "        print('already preprocessed!')\n",
    "        \n",
    "    return read_raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## metadata 'view' 전처리 (전체기간 동안의 조회수 view 저장)\n",
    "def metadata_view_preprocessing(metadata_df, read_raw_df):\n",
    "    \n",
    "    if 'view' in metadata_df.keys():\n",
    "        print('already preprocessed!')\n",
    "        \n",
    "    else:\n",
    "        view = read_raw_df.groupby('article_id').count()['user_id']\n",
    "        view_df = pd.DataFrame({'id':view.index, 'view':view.values})\n",
    "        metadata_df = pd.merge(metadata_df, view_df, how='left', on='id')\n",
    "        metadata_df['view'] = metadata_df['view'].fillna(0)\n",
    "        print(\"preprocessing completed!\")\n",
    "\n",
    "    return metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## target_df 생성 (users에 없는 user_id 추가)\n",
    "def target_df_generator(target_users_list, users_df):\n",
    "    \n",
    "    target_df = users_df[users_df['id'].isin(target_users_list)]\n",
    "    \n",
    "    for target_user in target_users_list:\n",
    "        if (target_user in target_df['id'].tolist()) == False:\n",
    "            new_df = pd.DataFrame({'following_list':[[]], 'id':[target_user], 'keyword_list':[[]]})\n",
    "            target_df = target_df.append(new_df)\n",
    "    print(\"preprocessing completed!\")\n",
    "    \n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## target_df 'read' 전처리 (전체 기간 동안 target user가 본 article을 저장)\n",
    "def target_read_article(target_df, read_raw_df, file):\n",
    "    \n",
    "    if os.path.isfile(file):        \n",
    "        with open(file,\"rb\") as fr:\n",
    "            target_read_article = pickle.load(fr)\n",
    "        print(\"target_read_article file loaded..\")\n",
    "\n",
    "        target_df['read'] = target_read_article\n",
    "        print(\"preprocessing completed!\")\n",
    "    \n",
    "    else:\n",
    "        target_read_article = []\n",
    "        iteration = 0\n",
    "        \n",
    "        # target user가 전체 기간 동안 본 글의 article_id 저장 (중복 허용)\n",
    "        for idx in target_df['id'].values.tolist():\n",
    "            read_list = read_raw_df[read_raw_df['user_id']==idx]['article_id'].values.tolist()\n",
    "            target_read_article.append(read_list)\n",
    "\n",
    "            # 진행 상황 표시\n",
    "            iteration += 1\n",
    "            print(iteration, '/', str(len(target_df['id'].values.tolist())), 'completed')\n",
    "            \n",
    "        with open(file,\"wb\") as fw:\n",
    "            pickle.dump(target_read_article, fw)\n",
    "        print(\"target_read_article file saved..\")\n",
    "        \n",
    "        target_df['read'] = target_read_article\n",
    "        print(\"preprocessing completed!\")\n",
    "            \n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_df 'following' 전처리 (전체 기간 동안 target user가 본 following의 빈도수 저장)\n",
    "def target_read_following(target_df, file):\n",
    "    \n",
    "    if os.path.isfile(file):\n",
    "        with open(file,\"rb\") as fr:\n",
    "            target_read_following = pickle.load(fr)\n",
    "        print(\"target_read_following file loaded..\")\n",
    "\n",
    "        target_df['read_following'] = target_read_following\n",
    "        print(\"preprocessing completed!\")\n",
    "    \n",
    "    else:\n",
    "        target_read_following = []\n",
    "        iteration = 0\n",
    "\n",
    "        for idx in target_df['id'].values.tolist():\n",
    "            # r_list- > target user의 read_list (읽은 글 리스트)\n",
    "            r_list = target_df[target_df['id']==idx]['read'].values[0][:]\n",
    "            r_series = pd.Series(r_list)\n",
    "\n",
    "            # f_list -> target user의 following_list (구독작가 리스트)\n",
    "            f_list = target_df[target_df['id']==idx]['following_list'].values[0][:]  \n",
    "            for i in range(len(f_list)):\n",
    "                f_list[i] = f_list[i] + '_'\n",
    "\n",
    "            # following_frequency -> r_list 중에서 해당 작가(f_id)의 글의 빈도수\n",
    "            following_frequency = {}\n",
    "            for f_id in f_list:\n",
    "                frequency = len(r_series[r_series.str.startswith(f_id)].tolist())\n",
    "                following_frequency[f_id[:-1]]=frequency\n",
    "            target_read_following.append(following_frequency)\n",
    "\n",
    "            # 진행 상황 표시\n",
    "            iteration += 1\n",
    "            print(iteration, '/', str(len(target_df['id'].values.tolist())), 'completed')\n",
    "            \n",
    "        with open(file,\"wb\") as fw:\n",
    "            pickle.dump(target_read_following, fw)\n",
    "        print(\"target_read_following file saved..\")\n",
    "        \n",
    "        target_df['read_following'] = target_read_following\n",
    "        print(\"preprocessing completed!\")\n",
    "    \n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_df 'magazine' 전처리 (전체 기간 동안 target user가 본 magazine의 빈도수 저장)\n",
    "def target_read_magazine(target_df, metadata_df, file):\n",
    "    \n",
    "    if os.path.isfile(file):\n",
    "        with open(file,\"rb\") as fr:\n",
    "            target_read_magazine = pickle.load(fr)\n",
    "        print(\"target_read_magazine file loaded..\")\n",
    "\n",
    "        target_df['read_magazine'] = target_read_magazine\n",
    "        print(\"preprocessing completed!\")\n",
    "    \n",
    "    else:\n",
    "        target_read_magazine = []\n",
    "        iteration = 0\n",
    "\n",
    "        for idx in target_df['id'].values.tolist():\n",
    "            # target user가 읽은 글의 magazine_id 저장\n",
    "            magazine_list = []\n",
    "            r_list = target_df[target_df['id']==idx]['read'].values[0][:]\n",
    "            magazine_list = metadata_df[metadata_df['id'].isin(r_list)]['magazine_id'].tolist()\n",
    "            \n",
    "            # magazine_id 빈도수 저장 (magazine이 아닌 0은 제외)\n",
    "            magazine_frequency = Counter(magazine_list)\n",
    "            del magazine_frequency[0]\n",
    "            target_read_magazine.append(magazine_frequency)\n",
    "\n",
    "            # 진행 상황 표시\n",
    "            iteration += 1\n",
    "            print(iteration, '/', str(len(target_df['id'].values.tolist())), 'completed')\n",
    "            \n",
    "        with open(file,\"wb\") as fw:\n",
    "            pickle.dump(target_read_magazine, fw)\n",
    "        print(\"target_read_magazine file saved..\")\n",
    "        \n",
    "        target_df['read_magazine'] = target_read_magazine\n",
    "        print(\"preprocessing completed!\")\n",
    "    \n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## target_df 'tag' 전처리 (일정 기간 동안 target user가 본 article의 tag 빈도수 저장)\n",
    "def target_read_tag(target_df, metadata_df, read_raw_df, from_dt, to_dt, file):\n",
    "    \n",
    "    if os.path.isfile(file):\n",
    "        with open(file,\"rb\") as fr:\n",
    "            target_read_tag = pickle.load(fr)\n",
    "        print(\"target_read_tag file loaded..\")\n",
    "\n",
    "        target_df['read_tag'] = target_read_tag\n",
    "        print(\"preprocessing completed!\")\n",
    "    \n",
    "    else:\n",
    "        target_read_tag = []\n",
    "        iteration = 0\n",
    "        \n",
    "        # 일정 기간(from_dt ~ to_dt) 동안 target user가 읽은 내역\n",
    "        partial_read = read_raw_df[(read_raw_df['dt'] >= from_dt) & (read_raw_df['dt'] <= to_dt)]\n",
    "\n",
    "        for idx in target_df['id'].values.tolist():\n",
    "            # 각 target user가 일정 기간 동안 읽은 article_id 리스트\n",
    "            partial_read_list = partial_read[partial_read['user_id']==idx]['article_id'].values.tolist()\n",
    "\n",
    "            # 각 target user가 일정 기간 동안 읽은 글의 태그 합쳐서 저장 (중복 허용)\n",
    "            partial_read_tag = []\n",
    "            \n",
    "            for i in range(len(partial_read_list)):\n",
    "                if len(metadata_df[metadata_df['id']==partial_read_list[i]]) > 0:\n",
    "                    tag = metadata_df[metadata_df['id']==partial_read_list[i]]['keyword_list'].values[0][:]\n",
    "                    partial_read_tag = partial_read_tag + tag\n",
    "            \n",
    "            # 각 target user가 일정 기간 동안 읽은 글의 태그들의 빈도수 저장\n",
    "            frequency = Counter(partial_read_tag)\n",
    "            target_read_tag.append(frequency)\n",
    "\n",
    "            # 진행 상황 표시\n",
    "            iteration += 1\n",
    "            print(iteration, '/', str(len(target_df['id'].values.tolist())), 'completed')\n",
    "        \n",
    "        with open(file,\"wb\") as fw:\n",
    "            pickle.dump(target_read_tag, fw)\n",
    "        print(\"target_read_tag file saved..\")\n",
    "        \n",
    "        target_df['read_tag'] = target_read_tag\n",
    "        print(\"preprocessing completed!\")        \n",
    "\n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## target_df 'interest' 전처리 (read_tag에서 빈도수가 높은 상위 top_N개 관심키워드 저장)\n",
    "def target_interest(target_df, top_N, file):\n",
    "    \n",
    "    if os.path.isfile(file):\n",
    "        with open(file,\"rb\") as fr:\n",
    "            target_interest = pickle.load(fr)\n",
    "        print(\"target_interest file loaded..\")\n",
    "\n",
    "        target_df['interest'] = target_interest\n",
    "        print(\"preprocessing completed!\")\n",
    "    \n",
    "    else:\n",
    "        target_interest = []\n",
    "        iteration = 0      \n",
    "        \n",
    "        # read_tag에서 빈도수가 높은 상위 top_N개의 키워드 저장\n",
    "        for idx in target_df['id'].values.tolist():\n",
    "            interest = []\n",
    "            \n",
    "            rt = target_df[target_df['id']==idx]['read_tag'].values[0]\n",
    "            sorted_rt = sorted(rt.items(), key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            for i in range(len(sorted_rt[:top_N])):\n",
    "                interest.append(sorted_rt[:top_N][i][0])\n",
    "                \n",
    "            target_interest.append(interest)\n",
    "            \n",
    "            # 진행 상황 표시\n",
    "            iteration += 1\n",
    "            print(iteration, '/', str(len(target_df['id'].values.tolist())), 'completed')\n",
    "        \n",
    "        with open(file,\"wb\") as fw:\n",
    "            pickle.dump(target_interest, fw)\n",
    "        print(\"target_interest file saved..\")\n",
    "        \n",
    "        target_df['interest'] = target_interest\n",
    "        print(\"preprocessing completed!\")        \n",
    "\n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_behavior(target_df):\n",
    "    f_ratio_list = []\n",
    "    m_ratio_list = []\n",
    "\n",
    "    for idx in target_df['id'].values.tolist():\n",
    "        r_list = target_df[target_df['id']==idx]['read'].values[0][:]\n",
    "\n",
    "        fr_dic = target_df[target_df['id']==idx]['read_following'].values[0]\n",
    "        mr_dic = target_df[target_df['id']==idx]['read_magazine'].values[0]\n",
    "\n",
    "        f_ratio = sum(fr_dic.values()) / len(r_list)\n",
    "        m_ratio = sum(mr_dic.values()) / len(r_list)      \n",
    "\n",
    "        f_ratio_list.append(round(f_ratio,2))\n",
    "        m_ratio_list.append(round(m_ratio,2))\n",
    "\n",
    "    target_df['f_ratio'] = f_ratio_list\n",
    "    target_df['m_ratio'] = m_ratio_list\n",
    "    print(\"preprocessing completed!\")\n",
    "    \n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 추천 관련 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item-based CF를 위한 item-user matrix 생성\n",
    "def item_user_df_generator(metadata_df, read_raw_df):\n",
    "\n",
    "    # users_read -> 전체 기간 동안 users가 읽은 article의 수 (중복 제거)\n",
    "    users_read = read_raw_df[['user_id','article_id']].drop_duplicates().groupby('user_id').count()\n",
    "    \n",
    "    # not_cold_start_users(ncsu) -> 읽은 article의 수가 평균보다 높은 users (평균 41개, 306,222 -> 55,416명)\n",
    "    not_cold_start_users = users_read[users_read['article_id'] > users_read['article_id'].mean()].index.tolist()\n",
    "\n",
    "    # not_long_tail_items(nlti) -> view가 상위 1%인 article (상위 1% 491건, 643,104 -> 6,424개)\n",
    "    not_long_tail_items = metadata_df[metadata_df['view'] > metadata_df['view'].quantile(0.99)]['id'].tolist()\n",
    "    \n",
    "    # ncsu와 nlti에 대해서 item-user matrix 생성 (6,424 * 55,416)\n",
    "    iu = read_raw_df[read_raw_df['user_id'].isin(not_cold_start_users) & read_raw_df['article_id'].isin(not_long_tail_items)]\n",
    "    iu = iu[['user_id','article_id']].drop_duplicates()\n",
    "    iu['read']=1\n",
    "    iu_df = iu.pivot(index='article_id', columns='user_id', values='read')\n",
    "    iu_df = iu_df.fillna(0)\n",
    "    \n",
    "    return iu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item-based CF 추천\n",
    "def collaborative_filtering(iu_df, file):\n",
    "\n",
    "    if os.path.isfile(file):        \n",
    "        with open(file,\"rb\") as fr:\n",
    "            cf_dic = pickle.load(fr)\n",
    "    \n",
    "    else:\n",
    "        # Step1: item-user martix에서 item에 대해 cosine similarity 구하기\n",
    "        cosine_array = cosine_similarity(iu_df, iu_df)\n",
    "\n",
    "        # Step 2: 가장 비슷한 10개의 item의 weighted mean을 이용해 predict\n",
    "        predicted_array = np.zeros(shape=(len(iu_df.index),len(iu_df.columns)))         \n",
    "            \n",
    "        for i in range(len(cosine_array)):\n",
    "            top_10 = cosine_array[i].argsort()[-11:][::-1]\n",
    "            top_10 = np.delete(top_10, 0)\n",
    "\n",
    "            weighted_sum = np.array([0])\n",
    "            for top_idx in top_10:\n",
    "                weighted_sum = weighted_sum + (cosine_array[i][top_idx] * iu_df.values[top_idx])\n",
    "            predicted = weighted_sum / len(top_10)\n",
    "            predicted_array[i] = predicted\n",
    "\n",
    "        iu_predicted = iu_df.values*(-99999) + predicted_array\n",
    "\n",
    "        # Step 3: 각 user에 대해 weighted mean이 높은 상위 100개 article을 저장\n",
    "        cf_dic = {}\n",
    "        for i in range(len(iu_predicted.T)):\n",
    "            cf_dic[iu_df.columns[i]] = iu_df.index[iu_predicted.T[i].argsort()[-100:][::-1]].tolist()\n",
    "\n",
    "        with open(file,\"wb\") as fw:\n",
    "            pickle.dump(cf_dic, fw)\n",
    "        \n",
    "    return cf_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target user가 읽은 글 중에서 구독작가 글의 비율을 고려하여 추천\n",
    "def following_based_recommend(idx, target_df, metadata_df, r_list, recommended, f_ratio):\n",
    "    \n",
    "    already = r_list + recommended\n",
    "    following_based_recommend_list = []\n",
    "    \n",
    "    # fr_dic -> {f_id,빈도수}\n",
    "    fr_dic = target_df[target_df['id']==idx]['read_following'].values[0]\n",
    "        \n",
    "    # sorted_fr -> 빈도수 순으로 정렬\n",
    "    sorted_fr = sorted(fr_dic.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for i in range(len(sorted_fr)):\n",
    "        if sorted_fr[i][1] > 0:\n",
    "            # n_rec -> 추천할 구독작가의 글의 개수 (빈도수가 높을수록 많이 추천됨)\n",
    "            n_rec = int( (100-len(recommended)) * f_ratio * (sorted_fr[i][1]/sum(fr_dic.values())) )\n",
    "            fr_article = metadata_df[metadata_df['user_id']==sorted_fr[i][0]]\n",
    "            # 이미 본 글이나 이미 추천된 글을 제외하고 reg_ts 순으로 n_rec만큼 추천\n",
    "            fr_candidate = fr_article[fr_article['id'].isin(already)==False].sort_values(['reg_ts'],ascending=[False])[:n_rec]['id'].tolist()\n",
    "            following_based_recommend_list = following_based_recommend_list + fr_candidate\n",
    "    \n",
    "    return following_based_recommend_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target user가 읽은 글 중에서 매거진 글의 비율을 고려하여 추천\n",
    "def magazine_based_recommend(idx, target_df, metadata_df, r_list, recommended, m_ratio):\n",
    "    \n",
    "    already = r_list + recommended\n",
    "    magazine_based_recommend_list = []\n",
    "    \n",
    "    # mr_dic -> {m_id : 빈도수}\n",
    "    mr_dic = target_df[target_df['id']==idx]['read_magazine'].values[0]\n",
    "    \n",
    "    # sorted_mr -> 빈도수 순으로 정렬\n",
    "    sorted_mr = sorted(mr_dic.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for i in range(len(sorted_mr)):\n",
    "        # n_rec -> 추천할 매거진 글의 개수 (빈도수가 높을수록 많이 추천됨)\n",
    "        n_rec = int( (100-len(recommended)) * (sorted_mr[i][1]/sum(mr_dic.values())) )\n",
    "        mr_article = metadata_df[metadata_df['magazine_id']==sorted_mr[i][0]]\n",
    "        # 이미 본 글이나 이미 추천된 글을 제외하고 reg_ts 순으로 n_rec만큼 추천\n",
    "        mr_candidate = mr_article[mr_article['id'].isin(already)==False].sort_values(['reg_ts'],ascending=[False])[:n_rec]['id'].tolist()\n",
    "        magazine_based_recommend_list = magazine_based_recommend_list + mr_candidate\n",
    "    \n",
    "    return magazine_based_recommend_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target user가 읽은 글들에서 자주 나오는 태그를 고려하여 추천\n",
    "def tag_based_recommend(idx, target_df, metadata_df, r_list, recommended):\n",
    "    \n",
    "    already = r_list + recommended\n",
    "\n",
    "    # user_interest -> target user의 interest (0 ~ 6개)\n",
    "    user_interest = target_df[target_df['id']== idx]['interest'].values[0][:]\n",
    "    \n",
    "    # interest_article_id -> target user의 interest와 2개 이상 겹치는 글의 article_id\n",
    "    interest_article_id = []\n",
    "    for i in range(len(metadata_df)):\n",
    "        if len(set(metadata_df['keyword_list'].values[i]) & set(user_interest)) >= 2:\n",
    "            interest_article_id.append(metadata['id'][i])\n",
    "\n",
    "    # 이미 본 글이나 이미 추천된 글을 제외하고 reg_ts 순으로 n_rec만큼 추천\n",
    "    n_rec = 100-len(recommended)\n",
    "    t_article = metadata_df[metadata_df['id'].isin(interest_article_id)]\n",
    "    tag_based_recommend_list = t_article[t_article['id'].isin(already)==False].sort_values(['reg_ts'],ascending=[False])[:n_rec]['id'].tolist()\n",
    "\n",
    "    return tag_based_recommend_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일정 기간 동안 조회수가 높은 인기 글을 추천\n",
    "def popularity_based_recommend(read_raw_df, r_list, recommended, from_dt, to_dt, file):\n",
    "    \n",
    "    already = r_list + recommended\n",
    "    \n",
    "    if os.path.isfile(file):\n",
    "        with open(file,\"rb\") as fr:\n",
    "            popularity = pickle.load(fr)\n",
    "            \n",
    "    else:\n",
    "        partial_read = read_raw_df[(read_raw_df['dt'] >= from_dt) & (read_raw_df['dt'] <= to_dt)]\n",
    "        available = partial_read[partial_read['article_id'].str.startswith('@')]\n",
    "        view = available.groupby('article_id').count()\n",
    "        popularity = view.sort_values(['user_id'], ascending=[False])['user_id']\n",
    "        popularity = popularity[popularity.keys().isin(metadata['id'].tolist())]\n",
    "        \n",
    "        # popularity 파일로 저장\n",
    "        with open(file,\"wb\") as fw:\n",
    "            pickle.dump(popularity, fw)\n",
    "        print(\"popularity file saved!\")\n",
    "    \n",
    "    candidate = popularity[popularity.keys().isin(already)==False]\n",
    "    popularity_based_recommend_list = candidate[:(100-len(recommended))].keys().tolist()\n",
    "\n",
    "    return popularity_based_recommend_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender(target_list, target_df, metadata_df, read_raw_df, min_view, pop_from, pop_to, pop_file, output_file):\n",
    "    \n",
    "    startTime = time.time()\n",
    "    \n",
    "    recommend_list = []\n",
    "    iteration = 0\n",
    "    \n",
    "    # metadata_min -> min_view보다 많은 view를 가진 글의 metadata\n",
    "    metadata_min = metadata_df[metadata_df['view'] > min_view]\n",
    "    \n",
    "    iu_df = item_user_df_generator(metadata_df, read_raw_df)\n",
    "    cf_dic = collaborative_filtering(iu_df, './pickle/cf_dic')\n",
    "\n",
    "    for idx in target_list:\n",
    "        recommended = []\n",
    "\n",
    "        r_list = target_df[target_df['id']==idx]['read'].values[0][:]\n",
    "        f_ratio = target_df[target_df['id']==idx]['f_ratio'].values[0]\n",
    "        m_ratio = target_df[target_df['id']==idx]['m_ratio'].values[0]\n",
    "        \n",
    "        # collaborative filtering 추천 (10개)\n",
    "        cf = []\n",
    "        if idx in cf_dic.keys():\n",
    "            cf = cf_dic[idx][:10]\n",
    "            recommended = recommended + cf\n",
    "\n",
    "        # following_based 추천\n",
    "        f = following_based_recommend(idx, target_df, metadata_min, r_list, recommended, f_ratio)\n",
    "        recommended = recommended + f\n",
    "\n",
    "        # magazine_based 추천\n",
    "        m = magazine_based_recommend(idx, target_df, metadata_min, r_list, recommended, m_ratio)\n",
    "        recommended = recommended + m\n",
    "\n",
    "        # tag_bsaed 추천\n",
    "        t = tag_based_recommend(idx, target_df, metadata_df, r_list, recommended)\n",
    "        recommended = recommended + t\n",
    "\n",
    "        # 100개 되지 않았다면 popularity_based 추천\n",
    "        p = []\n",
    "        if len(recommended) < 100:\n",
    "            p = popularity_based_recommend(read_raw_df, r_list, recommended, pop_from, pop_to, pop_file)\n",
    "            recommended = recommended + p\n",
    "            \n",
    "        # 추천 리스트 맨 앞에 user_id 추가\n",
    "        recommended.insert(0, idx)                \n",
    "        recommend_list.append(recommended)        \n",
    "\n",
    "\n",
    "        # 진행 상황 표시\n",
    "        iteration += 1\n",
    "        print(str(iteration).rjust(4), '/', str(len(target_list)), 'completed', '\\t', 'r_list:'+str(len(r_list)).rjust(5), '\\t', 'f_ratio:'+str(int(f_ratio*100)).rjust(3)+'%,', 'm_ratio:'+str(int(m_ratio*100)).rjust(3)+'%', '\\t', 'cf:'+str(len(cf)).rjust(2)+',' ,'f:'+str(len(f)).rjust(3)+',', 'm:'+str(len(m)).rjust(3)+',', 't:'+str(len(t)).rjust(3)+',', 'p:'+str(len(p)).rjust(3), '\\t','total:'+str(len(recommended)-1))\n",
    "\n",
    "\n",
    "    # 추천 리스트를 파일로 저장\n",
    "    f = open(output_file, 'w')\n",
    "    for i in range(len(recommend_list)):\n",
    "        for j in range(len(recommend_list[i])):\n",
    "            f.write(recommend_list[i][j])\n",
    "            if j == (len(recommend_list[i]) - 1):\n",
    "                continue\n",
    "            f.write(' ')\n",
    "        f.write('\\n')\n",
    "    f.close()\n",
    "    print('recommend.txt file saved..')\n",
    "    print('completed!')\n",
    "    \n",
    "    endTime = time.time() - startTime\n",
    "    print(int(endTime), 'seconds', '=', int(endTime/60), 'minutes')\n",
    "\n",
    "    return recommend_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 메인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. metadata & read_raw 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing completed!\n",
      "preprocessing completed!\n"
     ]
    }
   ],
   "source": [
    "read_raw = read_raw_dt_preprocessing(read_raw)\n",
    "metadata = metadata_view_preprocessing(metadata, read_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. target user 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing completed!\n",
      "target_read_article file loaded..\n",
      "preprocessing completed!\n",
      "target_read_following file loaded..\n",
      "preprocessing completed!\n",
      "target_read_magazine file loaded..\n",
      "preprocessing completed!\n",
      "target_read_tag file loaded..\n",
      "preprocessing completed!\n",
      "target_interest file loaded..\n",
      "preprocessing completed!\n",
      "preprocessing completed!\n"
     ]
    }
   ],
   "source": [
    "# dev에 대해 추천할 경우\n",
    "dev = target_df_generator(dev_users, users)\n",
    "dev = target_read_article(dev, read_raw, './pickle/dev_read_article')\n",
    "dev = target_read_following(dev, './pickle/dev_read_following')\n",
    "dev = target_read_magazine(dev, metadata, './pickle/dev_read_magazine')\n",
    "dev = target_read_tag(dev, metadata, read_raw, 20190222, 20190228, './pickle/dev_read_tag')\n",
    "dev = target_interest(dev, 6, './pickle/dev_interest_6')\n",
    "dev = target_behavior(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test에 대해 추천할 경우\n",
    "# test = target_df_generator(test_users, users)\n",
    "# test = target_read_article(test, read_raw, file='./pickle/test_read_article')\n",
    "# test = target_read_following(test, './pickle/test_read_following')\n",
    "# test = target_read_magazine(test, metadata, './pickle/test_read_magazine')\n",
    "# test = target_read_tag(test, metadata, read_raw, 20190222, 20190228, './pickle/test_read_tag')\n",
    "# test = target_interest(test, 6, './pickle/test_interest_6')\n",
    "# test = target_behavior(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. target user 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev에 대해 추천할 경우\n",
    "recommend = recommender(dev_users, dev, metadata, read_raw, 1, 20190222, 20190228, './pickle/popularity_190222_190228', './recommend.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test에 대해 추천할 경우\n",
    "# recommend = recommender(test_users, test, metadata, read_raw, 0, 20190222, 20190228, './pickle/popularity_190222_190228', './recommend.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
